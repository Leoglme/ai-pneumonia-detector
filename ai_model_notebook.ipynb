{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "693dae1a",
   "metadata": {},
   "source": [
    "\n",
    "# Zoidberg\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Ce projet vise à comparer deux approches de machine learning - les réseaux de neurones convolutifs (CNN) et les K-Nearest Neighbors (KNN) - pour détecter la pneumonie à partir d'images de radiographie. Nous évaluerons ces modèles en fonction de leur précision, de leur perte, et d'autres métriques pertinentes, incluant les faux négatifs, faux positifs, et des graphiques tels que la matrice de confusion et la courbe ROC.\n",
    "\n",
    "<style>\n",
    "h1 {color: navy;}\n",
    "h2 {color: navy;}\n",
    "</style>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a607c61c",
   "metadata": {},
   "source": [
    "\n",
    "## Structure du Dataset\n",
    "\n",
    "Le dataset se compose de trois dossiers principaux :\n",
    "- **train** : utilisé pour l'entraînement des modèles\n",
    "- **val** : utilisé pour la validation des modèles après l'entraînement\n",
    "- **test** : utilisé pour tester les modèles\n",
    "\n",
    "Chaque dossier contient deux sous-dossiers :\n",
    "- **NORMAL** : contient des images de radiographies normales\n",
    "- **PNEUMONIA** : contient des images de radiographies avec pneumonie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c62a06",
   "metadata": {},
   "source": [
    "\n",
    "## Filtrage des images avec ImageUtils\n",
    "\n",
    "La classe ImageUtils est utilisée pour filtrer les images de radiographie afin de s'assurer qu'elles respectent certaines dimensions minimales. Elle permet aussi de récupérer des informations sur le contenu du dataset, comme par exemple le nombre total d'images, les tailles minimales et maximales, les largeurs et hauteurs moyennes, ainsi que le nombre d'images filtrées. Voici comment elle fonctionne :\n",
    "\n",
    "```python\n",
    "class ImageUtils:\n",
    "    @staticmethod\n",
    "    def filter_images(data_dir, img_size=(256, 256)):\n",
    "        \"\"\"\n",
    "        Filter out images that are too small and gather statistics on the image sizes.\n",
    "        \"\"\"\n",
    "        min_img_size = (img_size[0] * 2, img_size[1] * 2)\n",
    "        image_stats = {\n",
    "            'total_images': 0,\n",
    "            'min_size': (float('inf'), float('inf')),\n",
    "            'max_size': (0, 0),\n",
    "            'avg_width': 0,\n",
    "            'avg_height': 0,\n",
    "            'filtered_images': 0\n",
    "        }\n",
    "        filepaths = []\n",
    "        total_width, total_height = 0, 0\n",
    "\n",
    "        for dirpath, _, filenames in os.walk(data_dir):\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith(('png', 'jpg', 'jpeg')):\n",
    "                    filepath = os.path.join(dirpath, filename)\n",
    "                    with Image.open(filepath) as img:\n",
    "                        width, height = img.size\n",
    "                        image_stats['total_images'] += 1\n",
    "                        total_width += width\n",
    "                        total_height += height\n",
    "                        if width < min_img_size[0] or height < min_img_size[1]:\n",
    "                            image_stats['filtered_images'] += 1\n",
    "                        else:\n",
    "                            filepaths.append(filepath)\n",
    "                            image_stats['min_size'] = (\n",
    "                                min(image_stats['min_size'][0], width),\n",
    "                                min(image_stats['min_size'][1], height)\n",
    "                            )\n",
    "                            image_stats['max_size'] = (\n",
    "                                max(image_stats['max_size'][0], width),\n",
    "                                max(image_stats['max_size'][1], height)\n",
    "                            )\n",
    "                            image_stats['avg_width'] += width\n",
    "                            image_stats['avg_height'] += height\n",
    "\n",
    "        remaining_images = image_stats['total_images'] - image_stats['filtered_images']\n",
    "        if remaining_images > 0:\n",
    "            image_stats['avg_width'] /= remaining_images\n",
    "            image_stats['avg_height'] /= remaining_images\n",
    "\n",
    "        image_stats['avg_width'] = round(image_stats['avg_width'])\n",
    "        image_stats['avg_height'] = round(image_stats['avg_height'])\n",
    "\n",
    "        filtered_filepaths = [fp for fp in filepaths if\n",
    "                              Image.open(fp).size[0] >= min_img_size[0] and Image.open(fp).size[1] >=\n",
    "                              min_img_size[1]]\n",
    "        return filtered_filepaths, image_stats\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8b52f7",
   "metadata": {},
   "source": [
    "\n",
    "## Modèle KNN\n",
    "\n",
    "Le modèle KNN (K-Nearest Neighbors) est un modèle de machine learning simple mais efficace pour la classification. Voici comment il est construit et utilisé dans ce projet :\n",
    "\n",
    "### Prétraitement et création du dataset avec ImageUtils\n",
    "\n",
    "Pour le modèle KNN, nous utilisons la classe `ImageUtils` pour filtrer et prétraiter les images de notre dataset. Nous choisissons une taille d'image plus petite (64x64) pour réduire la complexité computationnelle :\n",
    "\n",
    "```python\n",
    "data_handler = DataHandler(data_directory, image_size=(64, 64))\n",
    "file_paths, image_stats = ImageUtils.filter_images(data_directory, img_size=(64, 64))\n",
    "train_df, val_df = data_handler._create_dataframe(file_paths)\n",
    "X_train, X_val, y_train, y_val = data_handler._create_datasets()\n",
    "```\n",
    "\n",
    "### Construction du modèle KNN\n",
    "\n",
    "Le modèle KNN est construit en utilisant la bibliothèque `scikit-learn`. Voici les étapes de construction :\n",
    "\n",
    "1. **Chargement et Prétraitement des Images** :\n",
    "\n",
    "```python\n",
    "X_train = np.array([self._load_image(fp) for fp in self.train_df['filepath']])\n",
    "y_train = np.array([1 if label == 'PNEUMONIA' else 0 for label in self.train_df['class']])\n",
    "\n",
    "X_val = np.array([self._load_image(fp) for fp in self.val_df['filepath']])\n",
    "y_val = np.array([1 if label == 'PNEUMONIA' else 0 for label in self.val_df['class']])\n",
    "```\n",
    "\n",
    "2. **Entraînement du modèle** :\n",
    "\n",
    "```python\n",
    "self.model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "self.scaler = StandardScaler()\n",
    "X_train = self.scaler.fit_transform(X_train)\n",
    "self.model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "3. **Évaluation du modèle** :\n",
    "\n",
    "```python\n",
    "X_val = self.scaler.transform(X_val)\n",
    "y_pred = self.model.predict(X_val)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "report = classification_report(y_val, y_pred, target_names=['NORMAL', 'PNEUMONIA'])\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "roc_auc = roc_auc_score(y_val, y_proba)\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_proba)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a7dee",
   "metadata": {},
   "source": [
    "\n",
    "## Résultats du modèle KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47716ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Chargement des résultats KNN\n",
    "with open(\"knn_results.json\", \"r\") as file:\n",
    "    knn_results = json.load(file)\n",
    "\n",
    "# Affichage des résultats KNN\n",
    "print(\"## Résultats du modèle KNN\\n- Précision: {}\".format(knn_results['accuracy']))\n",
    "print(\"- Rapport de classification:\\n{}\".format(knn_results['classification_report']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1e2728",
   "metadata": {},
   "source": [
    "\n",
    "### Graphique KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e9a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "\n",
    "# Chargement des résultats\n",
    "with open(\"knn_results.json\", \"r\") as file:\n",
    "    knn_results = json.load(file)\n",
    "\n",
    "# Convertir la matrice de confusion en tableau NumPy\n",
    "cm = np.array(knn_results['confusion_matrix'])\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(knn_results['fpr'], knn_results['tpr'], knn_results['roc_auc'])\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20230f8a",
   "metadata": {},
   "source": [
    "\n",
    "## Modèle CNN\n",
    "\n",
    "Le modèle CNN (Convolutional Neural Network) est un modèle de machine learning puissant pour la classification d'images. Voici comment il est construit et utilisé dans ce projet :\n",
    "\n",
    "### Prétraitement et création du dataset avec ImageUtils\n",
    "\n",
    "Pour le modèle CNN, nous utilisons également la classe `ImageUtils` pour filtrer et prétraiter les images\n",
    "\n",
    ", mais avec une taille d'image plus grande (256x256) pour exploiter pleinement la capacité du modèle CNN :\n",
    "\n",
    "```python\n",
    "data_handler = DataHandler(data_directory, image_size=(256, 256))\n",
    "file_paths, image_stats = ImageUtils.filter_images(data_directory, img_size=(256, 256))\n",
    "train_df, val_df = data_handler._create_dataframe(file_paths)\n",
    "train_ds = data_handler.get_dataset(data_handler.train_generator)\n",
    "val_ds = data_handler.get_dataset(data_handler.validation_generator)\n",
    "```\n",
    "\n",
    "### Construction du modèle CNN\n",
    "\n",
    "Le modèle CNN est construit en utilisant la bibliothèque `TensorFlow`. Voici les étapes de construction :\n",
    "\n",
    "1. **Définition de l'architecture du modèle** :\n",
    "\n",
    "```python\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=input_shape),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "2. **Entraînement du modèle** :\n",
    "\n",
    "```python\n",
    "history = self.model.fit(\n",
    "    train_ds,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=val_steps\n",
    ")\n",
    "self.model.summary()\n",
    "```\n",
    "\n",
    "3. **Évaluation du modèle** :\n",
    "\n",
    "```python\n",
    "loss, accuracy = self.model.evaluate(test_ds, steps=test_steps)\n",
    "y_true = []\n",
    "y_pred = []\n",
    "y_proba = []\n",
    "\n",
    "for x, y in test_ds.take(test_steps):\n",
    "    y_true.extend(y.numpy())\n",
    "    preds = self.model.predict(x)\n",
    "    y_pred.extend(np.where(preds >= 0.5, 1, 0))\n",
    "    y_proba.extend(preds)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred).flatten()\n",
    "y_proba = np.array(y_proba).flatten()\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "roc_auc = roc_auc_score(y_true, y_proba)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e27a2",
   "metadata": {},
   "source": [
    "\n",
    "## Résultats du modèle CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a93f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Chargement des résultats CNN\n",
    "with open(\"cnn_results.json\", \"r\") as file:\n",
    "    cnn_results = json.load(file)\n",
    "\n",
    "# Affichage des résultats CNN\n",
    "print(\"## Résultats du modèle CNN\\n- Précision de test: {}\".format(cnn_results['test_accuracy']))\n",
    "print(\"- Perte de test: {}\".format(cnn_results['test_loss']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e54cd",
   "metadata": {},
   "source": [
    "\n",
    "### Graphique CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "\n",
    "# Chargement des résultats\n",
    "with open(\"cnn_results.json\", \"r\") as file:\n",
    "    cnn_results = json.load(file)\n",
    "\n",
    "# Convertir la matrice de confusion en tableau NumPy\n",
    "cm = np.array(cnn_results['confusion_matrix'])\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NORMAL', 'PNEUMONIA'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "plot_roc_curve(cnn_results['fpr'], cnn_results['tpr'], cnn_results['roc_auc'])\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plot_confusion_matrix(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8418a9be",
   "metadata": {},
   "source": [
    "\n",
    "## Comparaison de la précision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628fce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Comparaison des résultats\n",
    "labels = ['KNN', 'CNN']\n",
    "accuracy = [knn_results['accuracy'], cnn_results['test_accuracy']]\n",
    "\n",
    "# Création des graphiques\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(labels, accuracy, color=['blue', 'green'])\n",
    "plt.title('Comparaison de la précision')\n",
    "plt.ylabel('Précision')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57cc9de",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "En comparant les deux modèles, nous observons que :\n",
    "\n",
    "- Le modèle CNN montre une meilleure précision et un score AUC ROC plus élevé.\n",
    "- Le modèle KNN reste une option valide et plus simple à implémenter.\n",
    "\n",
    "### Recommandations\n",
    "\n",
    "- **Modèle CNN** :\n",
    "  - Plus fiable et précis pour la détection de la pneumonie.\n",
    "  - Peut encore être amélioré avec un entraînement plus long.\n",
    "\n",
    "- **Modèle KNN** :\n",
    "  - Option simple et rapide à implémenter.\n",
    "  - Utile dans des scénarios avec des ressources informatiques limitées.\n",
    "\n",
    "Pour des applications nécessitant une haute précision et la capacité de traiter de grands ensembles de données avec des images complexes, le modèle CNN est recommandé. En revanche, pour des scénarios où les ressources informatiques sont limitées et une implémentation rapide est nécessaire, le modèle KNN peut être plus approprié.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
